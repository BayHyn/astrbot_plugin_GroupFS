# astrbot_plugin_GroupFS/main.py

# è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–: pip install croniter aiohttp chardet
import asyncio
import os
import datetime
from typing import List, Dict, Optional

import aiohttp
import chardet
import croniter

from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
import astrbot.api.message_components as Comp
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
from aiocqhttp.exceptions import ActionFailed

# ä» utils.py å¯¼å…¥è¾…åŠ©å‡½æ•°å’Œå¸¸é‡
from . import utils

@register(
    "astrbot_plugin_GroupFS",
    "Foolllll",
    "ç®¡ç†QQç¾¤æ–‡ä»¶",
    "0.6_debug", # æ ‡è®°ä¸ºè°ƒè¯•ç‰ˆæœ¬
    "https://github.com/Foolllll-J/astrbot_plugin_GroupFS"
)
class GroupFSPlugin(Star):
    def __init__(self, context: Context, config: Optional[Dict] = None):
        super().__init__(context)
        self.config = config if config else {}
        self.group_whitelist: List[int] = [int(g) for g in self.config.get("group_whitelist", [])]
        self.admin_users: List[int] = [int(u) for u in self.config.get("admin_users", [])]
        self.preview_length: int = self.config.get("preview_length", 300)
        self.storage_limits: Dict[int, Dict] = {}
        self.cron_tasks = []
        self.last_cron_check_time: Dict[int, datetime.datetime] = {}
        self.bot = None

        limit_configs = self.config.get("storage_limits", [])
        for item in limit_configs:
            try:
                group_id_str, count_limit_str, space_limit_str = item.split(':')
                group_id = int(group_id_str)
                self.storage_limits[group_id] = {
                    "count_limit": int(count_limit_str),
                    "space_limit_gb": float(space_limit_str)
                }
            except ValueError as e:
                logger.error(f"è§£æ storage_limits é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        cron_configs = self.config.get("scheduled_check_tasks", [])
        for item in cron_configs:
            try:
                group_id_str, cron_str = item.split(':', 1)
                group_id = int(group_id_str)
                if not croniter.croniter.is_valid(cron_str):
                    raise ValueError(f"æ— æ•ˆçš„ cron è¡¨è¾¾å¼: {cron_str}")
                self.cron_tasks.append((group_id, cron_str))
            except ValueError as e:
                logger.error(f"è§£æ scheduled_check_tasks é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        self.last_check_date: str = self.config.get("last_check_date", "")
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²åŠ è½½ã€‚")

    async def initialize(self):
        if self.cron_tasks:
            logger.info("[å®šæ—¶ä»»åŠ¡] å¯åŠ¨å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥å¾ªç¯...")
            asyncio.create_task(self.scheduled_check_loop())

    async def scheduled_check_loop(self):
        await asyncio.sleep(10)
        while True:
            now = datetime.datetime.now()
            await asyncio.sleep(60 - now.second)
            now = datetime.datetime.now()
            for group_id, cron_str in self.cron_tasks:
                if croniter.croniter.match(cron_str, now):
                    last_check = self.last_cron_check_time.get(group_id)
                    if last_check and last_check.minute == now.minute and last_check.hour == now.hour:
                        continue
                    logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] Cron è¡¨è¾¾å¼ '{cron_str}' å·²è§¦å‘ï¼Œå¼€å§‹æ‰§è¡Œã€‚")
                    self.last_cron_check_time[group_id] = now
                    asyncio.create_task(self._perform_batch_check_for_cron(group_id))

    async def _perform_batch_check_for_cron(self, group_id: int):
        try:
            if not self.bot:
                logger.warning(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ— æ³•æ‰§è¡Œï¼Œå› ä¸ºå°šæœªæ•è·åˆ° bot å®ä¾‹ã€‚è¯·å…ˆè§¦å‘ä»»æ„ä¸€æ¬¡æŒ‡ä»¤ã€‚")
                return
            bot = self.bot
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, bot)
            # ... (æ­¤å¤„çœç•¥å®šæ—¶ä»»åŠ¡çš„æ ¸å¿ƒé€»è¾‘ï¼Œå› ä¸ºå®ƒä¸ /cf çš„æ ¸å¿ƒé€»è¾‘ _perform_batch_check ç±»ä¼¼)
        except Exception as e:
            logger.error(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)

    async def _get_all_files_recursive_core(self, group_id: int, bot) -> List[Dict]:
        all_files = []
        folders_to_scan = [(None, "æ ¹ç›®å½•")]
        logger.info(f"[{group_id}] [é€’å½’æŸ¥æ‰¾] å¼€å§‹è·å–æ–‡ä»¶åˆ—è¡¨...")
        while folders_to_scan:
            current_folder_id, current_folder_name = folders_to_scan.pop(0)
            try:
                logger.info(f"[{group_id}] [é€’å½’æŸ¥æ‰¾] ==> æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: '{current_folder_name}' (ID: {current_folder_id})")
                if current_folder_id is None:
                    result = await bot.api.call_action('get_group_root_files', group_id=group_id, file_count=2000)
                else:
                    result = await bot.api.call_action('get_group_files_by_folder', group_id=group_id, folder_id=current_folder_id, file_count=2000)
                
                logger.info(f"[{group_id}] [é€’å½’æŸ¥æ‰¾] æ–‡ä»¶å¤¹ '{current_folder_name}' çš„APIåŸå§‹å“åº”: {result}")

                if not result: 
                    logger.warning(f"[{group_id}] [é€’å½’æŸ¥æ‰¾] æ–‡ä»¶å¤¹ '{current_folder_name}' æœªè¿”å›ä»»ä½•ç»“æœã€‚")
                    continue

                files_in_folder = result.get('files', [])
                folders_in_folder = result.get('folders', [])
                logger.info(f"[{group_id}] [é€’å½’æŸ¥æ‰¾] åœ¨ '{current_folder_name}' ä¸­æ‰¾åˆ° {len(files_in_folder)} ä¸ªæ–‡ä»¶ å’Œ {len(folders_in_folder)} ä¸ªå­æ–‡ä»¶å¤¹ã€‚")

                if files_in_folder:
                    for file_info in files_in_folder:
                        file_info['parent_folder_name'] = current_folder_name
                        all_files.append(file_info)
                if folders_in_folder:
                    for folder in folders_in_folder:
                        if folder_id := folder.get('folder_id'):
                            folders_to_scan.append((folder_id, folder.get('folder_name')))
            except Exception as e:
                logger.error(f"[{group_id}] é€’å½’è·å–æ–‡ä»¶å¤¹ '{current_folder_name}' å†…å®¹æ—¶å‡ºé”™: {e}", exc_info=True)
                continue
        logger.info(f"[{group_id}] [é€’å½’æŸ¥æ‰¾] åˆ—è¡¨è·å–å®Œæˆï¼Œå…±è®¡ {len(all_files)} ä¸ªæ–‡ä»¶ã€‚")
        return all_files

    async def _trigger_daily_check_if_needed(self, event: AstrMessageEvent):
        today_str = datetime.date.today().isoformat()
        if self.last_check_date != today_str:
            group_id = int(event.get_group_id())
            logger.info(f"[{group_id}] [æ¯æ—¥è‡ªåŠ¨æ£€æŸ¥] æ£€æµ‹åˆ°ä»Šæ—¥å°šæœªæ£€æŸ¥ï¼Œå°†è‡ªåŠ¨å¯åŠ¨ä¸€æ¬¡å¤±æ•ˆæ–‡ä»¶æ‰«æ...")
            self.last_check_date = today_str
            self.config["last_check_date"] = today_str
            try:
                self.context.save_config()
            except Exception:
                logger.warning(f"[{group_id}] å½“å‰ AstrBot ç‰ˆæœ¬ä¼¼ä¹ä¸æ”¯æŒ context.save_config()ï¼Œè¯·æ‰‹åŠ¨ä¿å­˜é…ç½®ä»¥è®°å½•æ£€æŸ¥æ—¥æœŸã€‚")
            asyncio.create_task(self._perform_batch_check(event, is_daily_check=True))

    @filter.command("cdf")
    async def on_check_and_delete_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        await self._trigger_daily_check_if_needed(event)
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cdf å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŒ‡ä»¤ã€‚")
        await event.send(MessageChain([Comp.Plain("âš ï¸ è­¦å‘Šï¼šå³å°†å¼€å§‹æ‰«æå¹¶è‡ªåŠ¨åˆ é™¤æ‰€æœ‰å¤±æ•ˆæ–‡ä»¶ï¼\næ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå®Œæˆåå°†å‘é€æŠ¥å‘Šã€‚")]))
        asyncio.create_task(self._perform_batch_check_and_delete(event))
        event.stop_event()

    async def _perform_batch_check_and_delete(self, event: AstrMessageEvent):
        # ... (æ­¤å‡½æ•°ä¿æŒä¸å˜)
        group_id = int(event.get_group_id())
        try:
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, event.bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹å¤„ç†ã€‚")
            deleted_files = []
            failed_deletions = []
            checked_count = 0
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{ -(-total_count // batch_size)}...")
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    file_name = file_info.get("file_name", "æœªçŸ¥æ–‡ä»¶å")
                    if not file_id: continue
                    is_invalid = False
                    try:
                        await event.bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            is_invalid = True
                    if is_invalid:
                        logger.warning(f"[{group_id}] [æ‰¹é‡æ¸…ç†] å‘ç°å¤±æ•ˆæ–‡ä»¶ '{file_name}'ï¼Œå°è¯•åˆ é™¤...")
                        try:
                            delete_result = await event.bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
                            is_success = False
                            if delete_result:
                                trans_result = delete_result.get('transGroupFileResult', {})
                                result_obj = trans_result.get('result', {})
                                if result_obj.get('retCode') == 0:
                                    is_success = True
                            if is_success:
                                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æˆåŠŸåˆ é™¤å¤±æ•ˆæ–‡ä»¶: '{file_name}'")
                                deleted_files.append(file_name)
                            else:
                                logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] åˆ é™¤å¤±æ•ˆæ–‡ä»¶ '{file_name}' å¤±è´¥ï¼ŒAPIæœªè¿”å›æˆåŠŸã€‚")
                                failed_deletions.append(file_name)
                        except Exception as del_e:
                            logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] åˆ é™¤å¤±æ•ˆæ–‡ä»¶ '{file_name}' æ—¶å‘ç”Ÿå¼‚å¸¸: {del_e}")
                            failed_deletions.append(file_name)
                    checked_count += 1
                    await asyncio.sleep(0.2)
                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œå·²æ£€æŸ¥ {checked_count}/{total_count} ä¸ªæ–‡ä»¶ã€‚")
            report_message = f"âœ… æ¸…ç†å®Œæˆï¼\nå…±æ‰«æäº† {total_count} ä¸ªæ–‡ä»¶ã€‚\n\n"
            if deleted_files:
                report_message += f"æˆåŠŸåˆ é™¤äº† {len(deleted_files)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
                report_message += "\n".join(f"- {name}" for name in deleted_files)
            else:
                report_message += "æœªå‘ç°æˆ–æœªæˆåŠŸåˆ é™¤ä»»ä½•å¤±æ•ˆæ–‡ä»¶ã€‚"
            if failed_deletions:
                report_message += f"\n\nğŸš¨ æœ‰ {len(failed_deletions)} ä¸ªå¤±æ•ˆæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å¤„ç†ï¼š\n"
                report_message += "\n".join(f"- {name}" for name in failed_deletions)
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await event.send(MessageChain([Comp.Plain(report_message)]))
        except Exception as e:
            logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ åœ¨æ‰§è¡Œæ‰¹é‡æ¸…ç†æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    @filter.command("cf")
    async def on_check_files_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        await self._trigger_daily_check_if_needed(event)
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cf å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŒ‡ä»¤ã€‚")
        await event.send(MessageChain([Comp.Plain("âœ… å·²å¼€å§‹æ‰«æç¾¤å†…æ‰€æœ‰æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±æ•ˆæ–‡ä»¶...\nè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")]))
        asyncio.create_task(self._perform_batch_check(event))
        event.stop_event()

    async def _perform_batch_check(self, event: AstrMessageEvent, is_daily_check: bool = False):
        group_id = int(event.get_group_id())
        try:
            log_prefix = "[æ¯æ—¥è‡ªåŠ¨æ£€æŸ¥]" if is_daily_check else "[æ‰¹é‡æ£€æŸ¥]"
            logger.info(f"[{group_id}] {log_prefix} å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, event.bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] {log_prefix} è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹æ£€æŸ¥ã€‚")
            invalid_files_info = []
            checked_count = 0
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                logger.info(f"[{group_id}] {log_prefix} æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{ -(-total_count // batch_size)}...")
                for file_info in batch:
                    checked_count += 1
                    file_id = file_info.get("file_id")
                    file_name = file_info.get("file_name")
                    
                    logger.info(f"[{group_id}] {log_prefix} ({checked_count}/{total_count}) å‡†å¤‡æ£€æŸ¥æ–‡ä»¶: {file_info}")
                    
                    if not file_id:
                        logger.warning(f"[{group_id}] {log_prefix} æ–‡ä»¶ '{file_name}' ç¼ºå°‘ file_idï¼Œå·²è·³è¿‡ã€‚")
                        continue
                    
                    try:
                        await event.bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                        logger.info(f"[{group_id}] {log_prefix} æ–‡ä»¶ '{file_name}' æ£€æŸ¥æˆåŠŸï¼Œæ˜¯æœ‰æ•ˆæ–‡ä»¶ã€‚")
                    except ActionFailed as e:
                        logger.error(f"[{group_id}] {log_prefix} æ–‡ä»¶ '{file_name}' æ£€æŸ¥å¤±è´¥ï¼APIè¿”å› ActionFailedã€‚")
                        logger.error(f"[{group_id}] {log_prefix} å®Œæ•´çš„å¼‚å¸¸å¯¹è±¡ e: {e}")
                        logger.error(f"[{group_id}] {log_prefix} å¼‚å¸¸å†…éƒ¨çš„ result å­—å…¸ e.result: {e.result}")
                        
                        if e.result.get('retcode') == 1200:
                            logger.warning(f"[{group_id}] {log_prefix} åˆ¤å®šå¤±æ•ˆæ–‡ä»¶: '{file_info.get('file_name')}'ï¼Œé”™è¯¯: {e.result.get('wording')}")
                            invalid_files_info.append(file_info)
                    except Exception as e_general:
                         logger.error(f"[{group_id}] {log_prefix} æ–‡ä»¶ '{file_name}' æ£€æŸ¥æ—¶é‡åˆ°æœªçŸ¥é”™è¯¯: {e_general}", exc_info=True)

                    await asyncio.sleep(0.2)
                logger.info(f"[{group_id}] {log_prefix} æ‰¹æ¬¡å¤„ç†å®Œæ¯•ã€‚")

            report_title = "æ¯æ—¥æ£€æŸ¥æŠ¥å‘Š" if is_daily_check else "æ£€æŸ¥å®Œæˆï¼"
            if not invalid_files_info:
                report_message = f"ğŸ‰ {report_title}\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œæœªå‘ç°ä»»ä½•å¤±æ•ˆæ–‡ä»¶ã€‚"
            else:
                report_message = f"ğŸš¨ {report_title}\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œå…±å‘ç° {len(invalid_files_info)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
                report_message += "-" * 20
                for info in invalid_files_info:
                    folder_name = info.get('parent_folder_name', 'æœªçŸ¥')
                    modify_time = utils.format_timestamp(info.get('modify_time'))
                    report_message += f"\n- {info.get('file_name')}"
                    report_message += f"\n  (æ–‡ä»¶å¤¹: {folder_name} | æ—¶é—´: {modify_time})"
                report_message += "\n" + "-" * 20
                report_message += "\nå»ºè®®ä½¿ç”¨ /cdf æŒ‡ä»¤è¿›è¡Œä¸€é”®æ¸…ç†ã€‚"
            
            logger.info(f"[{group_id}] {log_prefix} æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await event.send(MessageChain([Comp.Plain(report_message)]))
        except Exception as e:
            logger.error(f"[{group_id}] {log_prefix} æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ åœ¨æ‰§è¡Œæ‰¹é‡æ£€æŸ¥æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))
    
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE)
    async def on_group_file_upload(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        has_file = any(isinstance(seg, Comp.File) for seg in event.get_messages())
        if has_file:
            group_id = int(event.get_group_id())
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°æ–‡ä»¶ä¸Šä¼ äº‹ä»¶ï¼Œå°†åœ¨5ç§’åè§¦å‘å®¹é‡æ£€æŸ¥ã€‚")
            await asyncio.sleep(5) 
            await self._check_storage_and_notify(event)

    async def _check_storage_and_notify(self, event: AstrMessageEvent):
        group_id = int(event.get_group_id())
        if group_id not in self.storage_limits:
            return
        try:
            client = event.bot
            system_info = await client.api.call_action('get_group_file_system_info', group_id=group_id)
            if not system_info: return
            file_count = system_info.get('file_count', 0)
            used_space_bytes = system_info.get('used_space', 0)
            used_space_gb = float(utils.format_bytes(used_space_bytes, 'GB'))
            limits = self.storage_limits[group_id]
            count_limit = limits['count_limit']
            space_limit = limits['space_limit_gb']
            notifications = []
            if file_count >= count_limit:
                notifications.append(f"æ–‡ä»¶æ•°é‡å·²è¾¾ {file_count}ï¼Œæ¥è¿‘æˆ–è¶…è¿‡è®¾å®šçš„ {count_limit} ä¸Šé™ï¼")
            if used_space_gb >= space_limit:
                notifications.append(f"å·²ç”¨ç©ºé—´å·²è¾¾ {used_space_gb:.2f}GBï¼Œæ¥è¿‘æˆ–è¶…è¿‡è®¾å®šçš„ {space_limit:.2f}GB ä¸Šé™ï¼")
            if notifications:
                full_notification = "âš ï¸ ç¾¤æ–‡ä»¶å®¹é‡è­¦å‘Š âš ï¸\n" + "\n".join(notifications) + "\nè¯·åŠæ—¶æ¸…ç†æ–‡ä»¶ï¼"
                logger.warning(f"[{group_id}] å‘é€å®¹é‡è¶…é™è­¦å‘Š: {full_notification}")
                await event.send(MessageChain([Comp.Plain(full_notification)]))
        except ActionFailed as e:
            logger.error(f"[{group_id}] è°ƒç”¨ get_group_file_system_info å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†å®¹é‡æ£€æŸ¥æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
    
    def _format_search_results(self, files: List[Dict], search_term: str, for_delete: bool = False) -> str:
        reply_text = f"ğŸ” æ‰¾åˆ°äº† {len(files)} ä¸ªä¸ã€Œ{search_term}ã€ç›¸å…³çš„ç»“æœï¼š\n"
        reply_text += "-" * 20
        for i, file_info in enumerate(files, 1):
            reply_text += (
                f"\n[{i}] {file_info.get('file_name')}"
                f"\n  ä¸Šä¼ è€…: {file_info.get('uploader_name', 'æœªçŸ¥')}"
                f"\n  å¤§å°: {utils.format_bytes(file_info.get('size'))}"
                f"\n  ä¿®æ”¹æ—¶é—´: {utils.format_timestamp(file_info.get('modify_time'))}"
            )
        reply_text += "\n" + "-" * 20
        if for_delete:
            reply_text += f"\nè¯·ä½¿ç”¨ /df {search_term} [åºå·] æ¥åˆ é™¤æŒ‡å®šæ–‡ä»¶ã€‚"
        else:
            reply_text += f"\nå¦‚éœ€åˆ é™¤ï¼Œè¯·ä½¿ç”¨ /df {search_term} [åºå·]"
        return reply_text
    
    @filter.command("sf")
    async def on_search_file_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦æœç´¢çš„æ–‡ä»¶åã€‚ç”¨æ³•: /sf <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /sf, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)
        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ã€‚")
        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªåœ¨ç¾¤æ–‡ä»¶ä¸­æ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
        if not index_str:
            reply_text = self._format_search_results(found_files, filename_to_find)
            await event.send(MessageChain([Comp.Plain(reply_text)]))
            return
        try:
            index = int(index_str)
            if not (1 <= index <= len(found_files)):
                await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                return
            file_to_preview = found_files[index - 1]
            preview_text, error_msg = await self._get_file_preview(event, file_to_preview)
            if error_msg:
                await event.send(MessageChain([Comp.Plain(error_msg)]))
                return
            reply_text = (
                f"ğŸ“„ æ–‡ä»¶ã€Œ{file_to_preview.get('file_name')}ã€å†…å®¹é¢„è§ˆï¼š\n"
                + "-" * 20 + "\n"
                + preview_text
            )
            await event.send(MessageChain([Comp.Plain(reply_text)]))
        except ValueError:
            await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ é¢„è§ˆæ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))
            
    @filter.command("df")
    async def on_delete_file_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦åˆ é™¤çš„æ–‡ä»¶åã€‚ç”¨æ³•: /df <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘åˆ é™¤æŒ‡ä»¤ /df, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)
        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ç”¨äºåˆ é™¤ã€‚")
        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªæ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
        if index_str == '0':
            asyncio.create_task(self._perform_batch_delete(event, found_files))
            event.stop_event()
            return
        file_to_delete = None
        if len(found_files) == 1 and not index_str:
            file_to_delete = found_files[0]
        elif index_str:
            try:
                index = int(index_str)
                if 1 <= index <= len(found_files):
                    file_to_delete = found_files[index - 1]
                else:
                    await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                    return
            except ValueError:
                await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
                return
        else:
            reply_text = self._format_search_results(found_files, filename_to_find, for_delete=True)
            await event.send(MessageChain([Comp.Plain(reply_text)]))
            return
        if not file_to_delete:
            await event.send(MessageChain([Comp.Plain("âŒ å†…éƒ¨é”™è¯¯ï¼Œæœªèƒ½ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶ã€‚")]))
            return
        try:
            file_id_to_delete = file_to_delete.get("file_id")
            found_filename = file_to_delete.get("file_name")
            if not file_id_to_delete:
                await event.send(MessageChain([Comp.Plain(f"âŒ æ‰¾åˆ°æ–‡ä»¶ã€Œ{found_filename}ã€ï¼Œä½†æ— æ³•è·å–å…¶IDï¼Œåˆ é™¤å¤±è´¥ã€‚")]))
                return
            logger.info(f"[{group_id}] ç¡®è®¤åˆ é™¤æ–‡ä»¶ '{found_filename}', File ID: {file_id_to_delete}...")
            client = event.bot
            delete_result = await client.api.call_action('delete_group_file', group_id=group_id, file_id=file_id_to_delete)
            is_success = False
            if delete_result:
                trans_result = delete_result.get('transGroupFileResult', {})
                result_obj = trans_result.get('result', {})
                if result_obj.get('retCode') == 0:
                    is_success = True
            if is_success:
                await event.send(MessageChain([Comp.Plain(f"âœ… æ–‡ä»¶ã€Œ{found_filename}ã€å·²æˆåŠŸåˆ é™¤ã€‚")]))
                logger.info(f"[{group_id}] æ–‡ä»¶ '{found_filename}' å·²æˆåŠŸåˆ é™¤ã€‚")
            else:
                error_msg = delete_result.get('wording', 'APIæœªè¿”å›æˆåŠŸçŠ¶æ€')
                await event.send(MessageChain([Comp.Plain(f"âŒ åˆ é™¤æ–‡ä»¶ã€Œ{found_filename}ã€å¤±è´¥: {error_msg}")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†åˆ é™¤æµç¨‹æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain(f"âŒ å¤„ç†åˆ é™¤æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    async def _perform_batch_delete(self, event: AstrMessageEvent, files_to_delete: List[Dict]):
        group_id = int(event.get_group_id())
        deleted_files = []
        failed_deletions = []
        total_count = len(files_to_delete)
        logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] å¼€å§‹å¤„ç† {total_count} ä¸ªæ–‡ä»¶çš„åˆ é™¤ä»»åŠ¡ã€‚")
        for i, file_info in enumerate(files_to_delete):
            file_id = file_info.get("file_id")
            file_name = file_info.get("file_name", "æœªçŸ¥æ–‡ä»¶å")
            if not file_id:
                failed_deletions.append(f"{file_name} (ç¼ºå°‘File ID)")
                continue
            try:
                logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] ({i+1}/{total_count}) æ­£åœ¨åˆ é™¤ '{file_name}'...")
                delete_result = await event.bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
                is_success = False
                if delete_result:
                    trans_result = delete_result.get('transGroupFileResult', {})
                    result_obj = trans_result.get('result', {})
                    if result_obj.get('retCode') == 0:
                        is_success = True
                if is_success:
                    deleted_files.append(file_name)
                else:
                    failed_deletions.append(file_name)
            except Exception as e:
                logger.error(f"[{group_id}] [æ‰¹é‡åˆ é™¤] åˆ é™¤ '{file_name}' æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                failed_deletions.append(file_name)
            await asyncio.sleep(0.5)
        report_message = f"âœ… æ‰¹é‡åˆ é™¤å®Œæˆï¼\nå…±å¤„ç†äº† {total_count} ä¸ªæ–‡ä»¶ã€‚\n\n"
        if deleted_files:
            report_message += f"æˆåŠŸåˆ é™¤äº† {len(deleted_files)} ä¸ªæ–‡ä»¶ï¼š\n"
            report_message += "\n".join(f"- {name}" for name in deleted_files)
        else:
            report_message += "æœªèƒ½æˆåŠŸåˆ é™¤ä»»ä½•æ–‡ä»¶ã€‚"
        if failed_deletions:
            report_message += f"\n\nğŸš¨ æœ‰ {len(failed_deletions)} ä¸ªæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼š\n"
            report_message += "\n".join(f"- {name}" for name in failed_deletions)
        logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] ä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
        await event.send(MessageChain([Comp.Plain(report_message)]))

    async def _get_file_preview(self, event: AstrMessageEvent, file_info: dict) -> tuple[str, str | None]:
        group_id = int(event.get_group_id())
        file_id = file_info.get("file_id")
        file_name = file_info.get("file_name", "")
        _, file_extension = os.path.splitext(file_name)
        if file_extension.lower() not in utils.SUPPORTED_PREVIEW_EXTENSIONS:
            return "", f"âŒ æ–‡ä»¶ã€Œ{file_name}ã€ä¸æ˜¯æ”¯æŒçš„æ–‡æœ¬æ ¼å¼ï¼Œæ— æ³•é¢„è§ˆã€‚"
        logger.info(f"[{group_id}] æ­£åœ¨ä¸ºæ–‡ä»¶ '{file_name}' (ID: {file_id}) è·å–é¢„è§ˆ...")
        try:
            client = event.bot
            url_result = await client.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
        except ActionFailed as e:
            logger.warning(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' ä¸‹è½½é“¾æ¥æ—¶APIè°ƒç”¨å¤±è´¥: {e}")
            if e.result.get('retcode') == 1200:
                error_message = (
                    f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ï¼š\n"
                    f"è¯¥æ–‡ä»¶å¯èƒ½å·²å¤±æ•ˆæˆ–è¢«æœåŠ¡å™¨æ¸…ç†ã€‚\n"
                    f"å»ºè®®ä½¿ç”¨ /df {os.path.splitext(file_name)[0]} å°†å…¶åˆ é™¤ã€‚"
                )
                return "", error_message
            else:
                return "", f"âŒ é¢„è§ˆå¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯ï¼š{e.result.get('wording', 'æœªçŸ¥é”™è¯¯')}"
        try:
            if not (url_result and url_result.get('url')):
                return "", f"âŒ æ— æ³•è·å–æ–‡ä»¶ã€Œ{file_name}ã€çš„ä¸‹è½½é“¾æ¥ã€‚"
            url = url_result['url']
            async with aiohttp.ClientSession() as session:
                headers = {'Range': 'bytes=0-4095'} 
                async with session.get(url, headers=headers, timeout=20) as resp:
                    if resp.status != 200 and resp.status != 206:
                        return "", f"âŒ ä¸‹è½½æ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ (HTTP: {resp.status})ã€‚"
                    content_bytes = await resp.read()
            if not content_bytes:
                return "ï¼ˆæ–‡ä»¶ä¸ºç©ºï¼‰", None
            detection = chardet.detect(content_bytes)
            encoding = detection.get('encoding', 'utf-8') or 'utf-8'
            decoded_text = content_bytes.decode(encoding, errors='ignore').strip()
            if len(decoded_text) > self.preview_length:
                return decoded_text[:self.preview_length] + "...", None
            return decoded_text, None
        except asyncio.TimeoutError:
            return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€è¶…æ—¶ã€‚"
        except Exception as e:
            logger.error(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"
            
    async def terminate(self):
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²å¸è½½ã€‚")