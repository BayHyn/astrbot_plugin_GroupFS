import asyncio
import os
import datetime
from typing import List, Dict, Optional
import zipfile
import chardet

import aiohttp
import croniter

from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
import astrbot.api.message_components as Comp
from astrbot.api.message_components import Node
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
from aiocqhttp.exceptions import ActionFailed

# ä» utils.py å¯¼å…¥è¾…åŠ©å‡½æ•°å’Œå¸¸é‡
from . import utils

@register(
    "astrbot_plugin_GroupFS",
    "Foolllll",
    "ç®¡ç†QQç¾¤æ–‡ä»¶",
    "0.8",
    "https://github.com/Foolllll-J/astrbot_plugin_GroupFS"
)
class GroupFSPlugin(Star):
    def __init__(self, context: Context, config: Optional[Dict] = None):
        super().__init__(context)
        self.config = config if config else {}
        self.group_whitelist: List[int] = [int(g) for g in self.config.get("group_whitelist", [])]
        self.admin_users: List[int] = [int(u) for u in self.config.get("admin_users", [])]
        self.preview_length: int = self.config.get("preview_length", 300)
        self.storage_limits: Dict[int, Dict] = {}
        self.cron_tasks = []
        self.last_cron_check_time: Dict[str, datetime.datetime] = {}
        self.bot = None
        self.forward_threshold: int = self.config.get("forward_threshold", 0)
        self.running_tasks = set()
        self.scheduler_lock = asyncio.Lock()
        
        # === æ–°å¢ Bot QQå·é…ç½®é¡¹ ===
        self.bot_qq_id = self.config.get("bot_qq_id")

        # === æ–°å¢ ZIP é¢„è§ˆç›¸å…³é…ç½®é¡¹ ===
        self.enable_zip_preview: bool = self.config.get("enable_zip_preview", False)
        self.default_zip_password: str = self.config.get("default_zip_password", "")
        self.download_semaphore = asyncio.Semaphore(5)

        # è§£æå®¹é‡ç›‘æ§é…ç½®
        limit_configs = self.config.get("storage_limits", [])
        for item in limit_configs:
            try:
                group_id_str, count_limit_str, space_limit_str = item.split(':')
                group_id = int(group_id_str)
                self.storage_limits[group_id] = { "count_limit": int(count_limit_str), "space_limit_gb": float(space_limit_str) }
            except ValueError as e:
                logger.error(f"è§£æ storage_limits é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        # è§£æå®šæ—¶ä»»åŠ¡é…ç½®
        cron_configs = self.config.get("scheduled_check_tasks", [])
        for item in cron_configs:
            try:
                group_id_str, cron_str = item.split(':', 1)
                group_id = int(group_id_str)
                if not croniter.croniter.is_valid(cron_str):
                    raise ValueError(f"æ— æ•ˆçš„ cron è¡¨è¾¾å¼: {cron_str}")
                task_key = f"{group_id}:{cron_str}"
                self.cron_tasks.append((task_key, group_id, cron_str))
            except ValueError as e:
                logger.error(f"è§£æ scheduled_check_tasks é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²åŠ è½½ã€‚")

    async def initialize(self):
        # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç­‰å¾…botè¿æ¥æˆåŠŸ
        asyncio.create_task(self._delayed_start_scheduler())

    async def _delayed_start_scheduler(self):
        """å»¶è¿Ÿå¯åŠ¨è°ƒåº¦å™¨ï¼Œç»™ç³»ç»Ÿæ—¶é—´åˆå§‹åŒ–"""
        try:
            # ç­‰å¾…10ç§’è®©ç³»ç»Ÿå®Œå…¨åˆå§‹åŒ–
            await asyncio.sleep(10)
            if self.cron_tasks:
                logger.info("[å®šæ—¶ä»»åŠ¡] å¯åŠ¨å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥å¾ªç¯...")
                asyncio.create_task(self.scheduled_check_loop())
        except Exception as e:
            logger.error(f"å»¶è¿Ÿå¯åŠ¨è°ƒåº¦å™¨å¤±è´¥: {e}", exc_info=True)

    def _get_bot(self) -> Optional[object]:
        """
        è·å–å¹¶æ›´æ–°botå®ä¾‹ã€‚
        ä¼˜å…ˆä» self.context è·å–ï¼Œå¦‚æœé…ç½®äº† bot_qq_idï¼Œåˆ™é€šè¿‡å®ƒåŒ¹é…ã€‚
        """
        if self.bot is None:
            if self.context and hasattr(self.context, "bot") and self.context.bot:
                # æ£€æŸ¥bot_qq_idæ˜¯å¦åŒ¹é…
                if self.bot_qq_id and str(self.context.bot.self_id) != str(self.bot_qq_id):
                    logger.warning(f"é…ç½®çš„ bot_qq_id ({self.bot_qq_id}) ä¸ AstrBot ä¸Šä¸‹æ–‡ä¸­çš„botä¸åŒ¹é… ({self.context.bot.self_id})ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
                    return None
                
                self.bot = self.context.bot
                logger.info(f"[Botå®ä¾‹] æˆåŠŸä» context ä¸­è·å–botå®ä¾‹ ({self.bot.self_id})ã€‚")
            else:
                logger.warning("[Botå®ä¾‹] æ— æ³•ä» context è·å–botå®ä¾‹ï¼Œå¯èƒ½å°šæœªè¿æ¥ã€‚")
        return self.bot
    
    async def _send_or_forward(self, event: AstrMessageEvent, text: str, name: str = "GroupFS"):
        if self.forward_threshold > 0 and len(text) > self.forward_threshold:
            group_id = int(event.get_group_id())
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°é•¿æ¶ˆæ¯ (é•¿åº¦: {len(text)} > {self.forward_threshold})ï¼Œå°†è‡ªåŠ¨åˆå¹¶è½¬å‘ã€‚")
            try:
                forward_node = Node(uin=event.get_self_id(), name=name, content=[Comp.Plain(text)])
                await event.send(MessageChain([forward_node]))
            except Exception as e:
                logger.error(f"[{group_id}] åˆå¹¶è½¬å‘é•¿æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
                await event.send(MessageChain([Comp.Plain(text[:self.forward_threshold] + "... (æ¶ˆæ¯è¿‡é•¿ä¸”åˆå¹¶è½¬å‘å¤±è´¥)")]))
        else:
            await event.send(MessageChain([Comp.Plain(text)]))

    async def scheduled_check_loop(self):
        await asyncio.sleep(10)
        while True:
            now = datetime.datetime.now()
            await asyncio.sleep(60 - now.second)
            
            async with self.scheduler_lock:
                now_aligned = datetime.datetime.now().replace(second=0, microsecond=0)
                for task_key, group_id, cron_str in self.cron_tasks:
                    if croniter.croniter.match(cron_str, now_aligned):
                        if task_key in self.running_tasks:
                            logger.warning(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ£€æµ‹åˆ°ä¸Šä¸€ä¸ªä»»åŠ¡ '{task_key}' ä»åœ¨è¿è¡Œï¼Œæœ¬æ¬¡è§¦å‘å·²è·³è¿‡ã€‚")
                            continue
                        logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] Cron è¡¨è¾¾å¼ '{cron_str}' å·²è§¦å‘ï¼Œå¼€å§‹æ‰§è¡Œã€‚")
                        self.running_tasks.add(task_key)
                        task = asyncio.ensure_future(self._perform_batch_check_for_cron(group_id))
                        task.add_done_callback(lambda t, key=task_key: self.running_tasks.remove(key))

    async def _perform_batch_check_for_cron(self, group_id: int):
        bot = self._get_bot()
        if not bot:
            logger.warning(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ— æ³•æ‰§è¡Œï¼Œå› ä¸ºå°šæœªè·å–åˆ° bot å®ä¾‹ã€‚")
            return
        
        try:
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹æ£€æŸ¥ã€‚")
            invalid_files_info = []
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    if not file_id: continue
                    try:
                        await bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            invalid_files_info.append(file_info)
                    await asyncio.sleep(0.2)
            if not invalid_files_info:
                logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ£€æŸ¥å®Œæˆï¼Œæœªå‘ç°å¤±æ•ˆæ–‡ä»¶ã€‚")
                return 
            report_message = f"ğŸš¨ å®šæ—¶æ£€æŸ¥æŠ¥å‘Š\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œå…±å‘ç° {len(invalid_files_info)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
            report_message += "-" * 20
            for info in invalid_files_info:
                folder_name = info.get('parent_folder_name', 'æœªçŸ¥')
                modify_time = utils.format_timestamp(info.get('modify_time'))
                report_message += f"\n- {info.get('file_name')}"
                report_message += f"\n  (æ–‡ä»¶å¤¹: {folder_name} | æ—¶é—´: {modify_time})"
            report_message += "\n" + "-" * 20
            report_message += "\nå»ºè®®ç®¡ç†å‘˜ä½¿ç”¨ /cdf æŒ‡ä»¤è¿›è¡Œä¸€é”®æ¸…ç†ã€‚"
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await bot.api.call_action('send_group_msg', group_id=group_id, message=report_message)
        except Exception as e:
            logger.error(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)

    async def _get_all_files_recursive_core(self, group_id: int, bot) -> List[Dict]:
        all_files = []
        folders_to_scan = [(None, "æ ¹ç›®å½•")]
        while folders_to_scan:
            current_folder_id, current_folder_name = folders_to_scan.pop(0)
            try:
                if current_folder_id is None:
                    result = await bot.api.call_action('get_group_root_files', group_id=group_id, file_count=2000)
                else:
                    result = await bot.api.call_action('get_group_files_by_folder', group_id=group_id, folder_id=current_folder_id, file_count=2000)
                if not result: continue
                if result.get('files'):
                    for file_info in result['files']:
                        file_info['parent_folder_name'] = current_folder_name
                        all_files.append(file_info)
                if result.get('folders'):
                    for folder in result['folders']:
                        if folder_id := folder.get('folder_id'):
                            folders_to_scan.append((folder_id, folder.get('folder_name')))
            except Exception as e:
                logger.error(f"[{group_id}] é€’å½’è·å–æ–‡ä»¶å¤¹ '{current_folder_name}' å†…å®¹æ—¶å‡ºé”™: {e}")
                continue
        return all_files
    
    @filter.command("cdf")
    async def on_check_and_delete_command(self, event: AstrMessageEvent):
        # ä¼˜å…ˆä»äº‹ä»¶ä¸­è·å–botå®ä¾‹ï¼Œå¹¶æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.bot = event.bot 
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cdf å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŒ‡ä»¤ã€‚")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        await event.send(MessageChain([Comp.Plain("âš ï¸ è­¦å‘Šï¼šå³å°†å¼€å§‹æ‰«æå¹¶è‡ªåŠ¨åˆ é™¤æ‰€æœ‰å¤±æ•ˆæ–‡ä»¶ï¼\næ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå®Œæˆåå°†å‘é€æŠ¥å‘Šã€‚")]))
        asyncio.create_task(self._perform_batch_check_and_delete(event))
        event.stop_event()

    async def _perform_batch_check_and_delete(self, event: AstrMessageEvent):
        group_id = int(event.get_group_id())
        bot = self._get_bot()
        if not bot:
            await event.send(MessageChain([Comp.Plain("âŒ æ— æ³•è·å–æœºå™¨äººå®ä¾‹ï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")]))
            return
        
        try:
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹å¤„ç†ã€‚")
            deleted_files = []
            failed_deletions = []
            checked_count = 0
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{ -(-total_count // batch_size)}...")
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    file_name = file_info.get("file_name", "æœªçŸ¥æ–‡ä»¶å")
                    if not file_id: continue
                    is_invalid = False
                    try:
                        await bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            is_invalid = True
                    if is_invalid:
                        logger.warning(f"[{group_id}] [æ‰¹é‡æ¸…ç†] å‘ç°å¤±æ•ˆæ–‡ä»¶ '{file_name}'ï¼Œå°è¯•åˆ é™¤...")
                        try:
                            delete_result = await bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
                            is_success = False
                            if delete_result:
                                trans_result = delete_result.get('transGroupFileResult', {})
                                result_obj = trans_result.get('result', {})
                                if result_obj.get('retCode') == 0:
                                    is_success = True
                            if is_success:
                                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æˆåŠŸåˆ é™¤å¤±æ•ˆæ–‡ä»¶: '{file_name}'")
                                deleted_files.append(file_name)
                            else:
                                logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] åˆ é™¤å¤±æ•ˆæ–‡ä»¶ '{file_name}' å¤±è´¥ï¼ŒAPIæœªè¿”å›æˆåŠŸã€‚")
                                failed_deletions.append(file_name)
                        except Exception as del_e:
                            logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] åˆ é™¤å¤±æ•ˆæ–‡ä»¶ '{file_name}' æ—¶å‘ç”Ÿå¼‚å¸¸: {del_e}")
                            failed_deletions.append(file_name)
                    checked_count += 1
                    await asyncio.sleep(0.2)
                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œå·²æ£€æŸ¥ {checked_count}/{total_count} ä¸ªæ–‡ä»¶ã€‚")
            report_message = f"âœ… æ¸…ç†å®Œæˆï¼\nå…±æ‰«æäº† {total_count} ä¸ªæ–‡ä»¶ã€‚\n\n"
            if deleted_files:
                report_message += f"æˆåŠŸåˆ é™¤äº† {len(deleted_files)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
                report_message += "\n".join(f"- {name}" for name in deleted_files)
            else:
                report_message += "æœªå‘ç°æˆ–æœªæˆåŠŸåˆ é™¤ä»»ä½•å¤±æ•ˆæ–‡ä»¶ã€‚"
            if failed_deletions:
                report_message += f"\n\nğŸš¨ æœ‰ {len(failed_deletions)} ä¸ªå¤±æ•ˆæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å¤„ç†ï¼š\n"
                report_message += "\n".join(f"- {name}" for name in failed_deletions)
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await self._send_or_forward(event, report_message, name="å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŠ¥å‘Š")
        except Exception as e:
            logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ åœ¨æ‰§è¡Œæ‰¹é‡æ¸…ç†æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    @filter.command("cf")
    async def on_check_files_command(self, event: AstrMessageEvent):
        # ä¼˜å…ˆä»äº‹ä»¶ä¸­è·å–botå®ä¾‹ï¼Œå¹¶æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cf å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŒ‡ä»¤ã€‚")
        await event.send(MessageChain([Comp.Plain("âœ… å·²å¼€å§‹æ‰«æç¾¤å†…æ‰€æœ‰æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±æ•ˆæ–‡ä»¶...\nè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")]))
        asyncio.create_task(self._perform_batch_check(event))
        event.stop_event()

    async def _perform_batch_check(self, event: AstrMessageEvent, is_daily_check: bool = False):
        group_id = int(event.get_group_id())
        bot = self._get_bot()
        if not bot:
            await event.send(MessageChain([Comp.Plain("âŒ æ— æ³•è·å–æœºå™¨äººå®ä¾‹ï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")]))
            return
        
        try:
            log_prefix = "[æ¯æ—¥è‡ªåŠ¨æ£€æŸ¥]" if is_daily_check else "[æ‰¹é‡æ£€æŸ¥]"
            logger.info(f"[{group_id}] {log_prefix} å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] {log_prefix} è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹æ£€æŸ¥ã€‚")
            invalid_files_info = []
            checked_count = 0
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                logger.info(f"[{group_id}] {log_prefix} æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{ -(-total_count // batch_size)}...")
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    if not file_id: continue
                    try:
                        await bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            logger.warning(f"[{group_id}] {log_prefix} åˆ¤å®šå¤±æ•ˆæ–‡ä»¶: '{file_info.get('file_name')}'ï¼Œé”™è¯¯: {e.result.get('wording')}")
                            invalid_files_info.append(file_info)
                    checked_count += 1
                    await asyncio.sleep(0.2)
                logger.info(f"[{group_id}] {log_prefix} æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œå·²æ£€æŸ¥ {checked_count}/{total_count} ä¸ªæ–‡ä»¶ã€‚")
            report_title = "æ¯æ—¥æ£€æŸ¥æŠ¥å‘Š" if is_daily_check else "æ£€æŸ¥å®Œæˆï¼"
            if not invalid_files_info:
                report_message = f"ğŸ‰ {report_title}\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œæœªå‘ç°ä»»ä½•å¤±æ•ˆæ–‡ä»¶ã€‚"
            else:
                report_message = f"ğŸš¨ {report_title}\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œå…±å‘ç° {len(invalid_files_info)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
                report_message += "-" * 20
                for info in invalid_files_info:
                    folder_name = info.get('parent_folder_name', 'æœªçŸ¥')
                    modify_time = utils.format_timestamp(info.get('modify_time'))
                    report_message += f"\n- {info.get('file_name')}"
                    report_message += f"\n  (æ–‡ä»¶å¤¹: {folder_name} | æ—¶é—´: {modify_time})"
                report_message += "\n" + "-" * 20
                report_message += "\nå»ºè®®ä½¿ç”¨ /cdf æŒ‡ä»¤è¿›è¡Œä¸€é”®æ¸…ç†ã€‚"
            logger.info(f"[{group_id}] {log_prefix} æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await self._send_or_forward(event, report_message, name="å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŠ¥å‘Š")
        except Exception as e:
            logger.error(f"[{group_id}] {log_prefix} æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ åœ¨æ‰§è¡Œæ‰¹é‡æ£€æŸ¥æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))
    
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE, priority=10)
    async def on_group_file_upload(self, event: AstrMessageEvent):
        # ä¼˜å…ˆä»äº‹ä»¶ä¸­è·å–botå®ä¾‹ï¼Œå¹¶æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.bot = event.bot
        has_file = any(isinstance(seg, Comp.File) for seg in event.get_messages())
        if has_file:
            group_id = int(event.get_group_id())
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°æ–‡ä»¶ä¸Šä¼ äº‹ä»¶ï¼Œå°†åœ¨5ç§’åè§¦å‘å®¹é‡æ£€æŸ¥ã€‚")
            await asyncio.sleep(5) 
            await self._check_storage_and_notify(event)

    async def _check_storage_and_notify(self, event: AstrMessageEvent):
        group_id = int(event.get_group_id())
        bot = self._get_bot()
        if not bot:
            logger.warning(f"[{group_id}] æ— æ³•æ‰§è¡Œå®¹é‡æ£€æŸ¥ï¼ŒBotå®ä¾‹ä¸å¯ç”¨ã€‚")
            return
            
        if group_id not in self.storage_limits:
            return
        try:
            client = bot
            system_info = await client.api.call_action('get_group_file_system_info', group_id=group_id)
            if not system_info: return
            file_count = system_info.get('file_count', 0)
            used_space_bytes = system_info.get('used_space', 0)
            used_space_gb = float(utils.format_bytes(used_space_bytes, 'GB'))
            limits = self.storage_limits[group_id]
            count_limit = limits['count_limit']
            space_limit = limits['space_limit_gb']
            notifications = []
            if file_count >= count_limit:
                notifications.append(f"æ–‡ä»¶æ•°é‡å·²è¾¾ {file_count}ï¼Œæ¥è¿‘æˆ–è¶…è¿‡è®¾å®šçš„ {count_limit} ä¸Šé™ï¼")
            if used_space_gb >= space_limit:
                notifications.append(f"å·²ç”¨ç©ºé—´å·²è¾¾ {used_space_gb:.2f}GBï¼Œæ¥è¿‘æˆ–è¶…è¿‡è®¾å®šçš„ {space_limit:.2f}GB ä¸Šé™ï¼")
            if notifications:
                full_notification = "âš ï¸ ç¾¤æ–‡ä»¶å®¹é‡è­¦å‘Š âš ï¸\n" + "\n".join(notifications) + "\nè¯·åŠæ—¶æ¸…ç†æ–‡ä»¶ï¼"
                logger.warning(f"[{group_id}] å‘é€å®¹é‡è¶…é™è­¦å‘Š: {full_notification}")
                await event.send(MessageChain([Comp.Plain(full_notification)]))
        except ActionFailed as e:
            logger.error(f"[{group_id}] è°ƒç”¨ get_group_file_system_info å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†å®¹é‡æ£€æŸ¥æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
    
    def _format_search_results(self, files: List[Dict], search_term: str, for_delete: bool = False) -> str:
        reply_text = f"ğŸ” æ‰¾åˆ°äº† {len(files)} ä¸ªä¸ã€Œ{search_term}ã€ç›¸å…³çš„ç»“æœï¼š\n"
        reply_text += "-" * 20
        for i, file_info in enumerate(files, 1):
            reply_text += (
                f"\n[{i}] {file_info.get('file_name')}"
                f"\n  ä¸Šä¼ è€…: {file_info.get('uploader_name', 'æœªçŸ¥')}"
                f"\n  å¤§å°: {utils.format_bytes(file_info.get('size'))}"
                f"\n  ä¿®æ”¹æ—¶é—´: {utils.format_timestamp(file_info.get('modify_time'))}"
            )
        reply_text += "\n" + "-" * 20
        if for_delete:
            reply_text += f"\nè¯·ä½¿ç”¨ /df {search_term} [åºå·] æ¥åˆ é™¤æŒ‡å®šæ–‡ä»¶ã€‚"
        else:
            reply_text += f"\nå¦‚éœ€åˆ é™¤ï¼Œè¯·ä½¿ç”¨ /df {search_term} [åºå·]"
        return reply_text
    
    @filter.command("sf")
    async def on_search_file_command(self, event: AstrMessageEvent):
        # ä¼˜å…ˆä»äº‹ä»¶ä¸­è·å–botå®ä¾‹ï¼Œå¹¶æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        bot = self._get_bot()
        if not bot:
            await event.send(MessageChain([Comp.Plain("âŒ æ— æ³•è·å–æœºå™¨äººå®ä¾‹ï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")]))
            return
            
        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦æœç´¢çš„æ–‡ä»¶åã€‚ç”¨æ³•: /sf <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /sf, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        
        all_files = await self._get_all_files_recursive_core(group_id, bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)
        
        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ã€‚")

        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªåœ¨ç¾¤æ–‡ä»¶ä¸­æ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
        if not index_str:
            reply_text = self._format_search_results(found_files, filename_to_find)
            await self._send_or_forward(event, reply_text, name="æ–‡ä»¶æœç´¢ç»“æœ")
            return
        try:
            index = int(index_str)
            if not (1 <= index <= len(found_files)):
                await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                return
            file_to_preview = found_files[index - 1]
            preview_text, error_msg = await self._get_file_preview(event, file_to_preview)
            if error_msg:
                # é¢„è§ˆå¤±è´¥ï¼Œç›´æ¥å‘é€é”™è¯¯ä¿¡æ¯
                await event.send(MessageChain([Comp.Plain(error_msg)]))
                return
            
            # é¢„è§ˆæˆåŠŸï¼Œæ„å»ºå›å¤æ¶ˆæ¯
            reply_text = (
                f"ğŸ“„ æ–‡ä»¶ã€Œ{file_to_preview.get('file_name')}ã€å†…å®¹é¢„è§ˆï¼š\n"
                + "-" * 20 + "\n"
                + preview_text
            )
            await self._send_or_forward(event, reply_text, name=f"æ–‡ä»¶é¢„è§ˆï¼š{file_to_preview.get('file_name')}")
        except ValueError:
            await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ é¢„è§ˆæ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))
            
    @filter.command("df")
    async def on_delete_file_command(self, event: AstrMessageEvent):
        # ä¼˜å…ˆä»äº‹ä»¶ä¸­è·å–botå®ä¾‹ï¼Œå¹¶æ›´æ–°æœ¬åœ°ç¼“å­˜
        self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        bot = self._get_bot()
        if not bot:
            await event.send(MessageChain([Comp.Plain("âŒ æ— æ³•è·å–æœºå™¨äººå®ä¾‹ï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")]))
            return

        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦åˆ é™¤çš„æ–‡ä»¶åã€‚ç”¨æ³•: /df <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘åˆ é™¤æŒ‡ä»¤ /df, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return

        all_files = await self._get_all_files_recursive_core(group_id, bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)

        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ç”¨äºåˆ é™¤ã€‚")
            
        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªæ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
            
        if index_str == '0':
            asyncio.create_task(self._perform_batch_delete(event, found_files))
            event.stop_event()
            return

        file_to_delete = None
        if len(found_files) == 1 and not index_str:
            file_to_delete = found_files[0]
        elif index_str:
            try:
                index = int(index_str)
                if 1 <= index <= len(found_files):
                    file_to_delete = found_files[index - 1]
                else:
                    await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                    return
            except ValueError:
                await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
                return
        else:
            reply_text = self._format_search_results(found_files, filename_to_find, for_delete=True)
            await self._send_or_forward(event, reply_text, name="æ–‡ä»¶æœç´¢ç»“æœ")
            return

        if not file_to_delete:
            await event.send(MessageChain([Comp.Plain("âŒ å†…éƒ¨é”™è¯¯ï¼Œæœªèƒ½ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶ã€‚")]))
            return
        try:
            file_id_to_delete = file_to_delete.get("file_id")
            found_filename = file_to_delete.get("file_name")
            if not file_id_to_delete:
                await event.send(MessageChain([Comp.Plain(f"âŒ æ‰¾åˆ°æ–‡ä»¶ã€Œ{found_filename}ã€ï¼Œä½†æ— æ³•è·å–å…¶IDï¼Œåˆ é™¤å¤±è´¥ã€‚")]))
                return
            logger.info(f"[{group_id}] ç¡®è®¤åˆ é™¤æ–‡ä»¶ '{found_filename}', File ID: {file_id_to_delete}...")
            delete_result = await bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id_to_delete)
            is_success = False
            if delete_result:
                trans_result = delete_result.get('transGroupFileResult', {})
                result_obj = trans_result.get('result', {})
                if result_obj.get('retCode') == 0:
                    is_success = True
            if is_success:
                await event.send(MessageChain([Comp.Plain(f"âœ… æ–‡ä»¶ã€Œ{found_filename}ã€å·²æˆåŠŸåˆ é™¤ã€‚")]))
                logger.info(f"[{group_id}] æ–‡ä»¶ '{found_filename}' å·²æˆåŠŸåˆ é™¤ã€‚")
            else:
                error_msg = delete_result.get('wording', 'APIæœªè¿”å›æˆåŠŸçŠ¶æ€')
                await event.send(MessageChain([Comp.Plain(f"âŒ åˆ é™¤æ–‡ä»¶ã€Œ{found_filename}ã€å¤±è´¥: {error_msg}")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†åˆ é™¤æµç¨‹æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain(f"âŒ å¤„ç†åˆ é™¤æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    async def _perform_batch_delete(self, event: AstrMessageEvent, files_to_delete: List[Dict]):
        group_id = int(event.get_group_id())
        bot = self._get_bot()
        if not bot:
            await event.send(MessageChain([Comp.Plain("âŒ æ— æ³•è·å–æœºå™¨äººå®ä¾‹ï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")]))
            return

        deleted_files = []
        failed_deletions = []
        total_count = len(files_to_delete)
        logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] å¼€å§‹å¤„ç† {total_count} ä¸ªæ–‡ä»¶çš„åˆ é™¤ä»»åŠ¡ã€‚")
        for i, file_info in enumerate(files_to_delete):
            file_id = file_info.get("file_id")
            file_name = file_info.get("file_name", "æœªçŸ¥æ–‡ä»¶å")
            if not file_id:
                failed_deletions.append(f"{file_name} (ç¼ºå°‘File ID)")
                continue
            try:
                logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] ({i+1}/{total_count}) æ­£åœ¨åˆ é™¤ '{file_name}'...")
                delete_result = await bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
                is_success = False
                if delete_result:
                    trans_result = delete_result.get('transGroupFileResult', {})
                    result_obj = trans_result.get('result', {})
                    if result_obj.get('retCode') == 0:
                        is_success = True
                if is_success:
                    deleted_files.append(file_name)
                else:
                    failed_deletions.append(file_name)
            except Exception as e:
                logger.error(f"[{group_id}] [æ‰¹é‡åˆ é™¤] åˆ é™¤ '{file_name}' æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                failed_deletions.append(file_name)
            await asyncio.sleep(0.5)
        report_message = f"âœ… æ‰¹é‡åˆ é™¤å®Œæˆï¼\nå…±å¤„ç†äº† {total_count} ä¸ªæ–‡ä»¶ã€‚\n\n"
        if deleted_files:
            report_message += f"æˆåŠŸåˆ é™¤äº† {len(deleted_files)} ä¸ªæ–‡ä»¶ï¼š\n"
            report_message += "\n".join(f"- {name}" for name in deleted_files)
        else:
            report_message += "æœªèƒ½æˆåŠŸåˆ é™¤ä»»ä½•æ–‡ä»¶ã€‚"
        if failed_deletions:
            report_message += f"\n\nğŸš¨ æœ‰ {len(failed_deletions)} ä¸ªæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼š\n"
            report_message += "\n".join(f"- {name}" for name in failed_deletions)
        logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] ä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
        await self._send_or_forward(event, report_message, name="æ‰¹é‡åˆ é™¤æŠ¥å‘Š")
    
    def _get_preview_from_bytes(self, content_bytes: bytes) -> tuple[str, str]:
        """ä»å­—èŠ‚å†…å®¹ä¸­å°è¯•è·å–æ–‡æœ¬é¢„è§ˆå’Œç¼–ç ã€‚"""
        try:
            detection = chardet.detect(content_bytes)
            encoding = detection.get('encoding', 'utf-8') or 'utf-8'
            if encoding and detection['confidence'] > 0.7:
                decoded_text = content_bytes.decode(encoding, errors='ignore').strip()
                return decoded_text, encoding
            return "", "æœªçŸ¥"
        except Exception:
            return "", "æœªçŸ¥"

    def _fix_zip_filename(self, filename: str) -> str:
        """ä¿®å¤ZIPæ–‡ä»¶ä¸­çš„ä¹±ç æ–‡ä»¶åã€‚"""
        try:
            return filename.encode('cp437').decode('gbk')
        except (UnicodeEncodeError, UnicodeDecodeError):
            return filename
    
    async def _get_preview_from_zip(self, file_path: str) -> tuple[str, str]:
        """ä»æœ¬åœ°ZIPæ–‡ä»¶ä¸­è§£å‹å¹¶é¢„è§ˆç¬¬ä¸€ä¸ªTXTæ–‡ä»¶ã€‚è¿”å› (é¢„è§ˆå†…å®¹, é”™è¯¯ä¿¡æ¯)ã€‚"""
        def _try_unzip(pwd: Optional[str] = None) -> Optional[tuple[bytes, str]]:
            with zipfile.ZipFile(file_path, 'r') as zf:
                if pwd:
                    zf.setpassword(pwd.encode('utf-8'))
                txt_files_garbled = sorted([f for f in zf.namelist() if f.lower().endswith('.txt')])
                if not txt_files_garbled:
                    return None
                first_txt_garbled = txt_files_garbled[0]
                first_txt_fixed = self._fix_zip_filename(first_txt_garbled)
                content_bytes = zf.read(first_txt_garbled)
                return content_bytes, first_txt_fixed

        content_bytes, inner_filename = None, None
        try:
            result = await asyncio.to_thread(_try_unzip)
            if result:
                content_bytes, inner_filename = result
        except RuntimeError:
            logger.info(f"æ— å¯†ç è§£å‹ '{os.path.basename(file_path)}' å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å¯†ç ...")
            try:
                if self.default_zip_password:
                    result = await asyncio.to_thread(_try_unzip, self.default_zip_password)
                    if result:
                        content_bytes, inner_filename = result
                    else:
                        return "", "å‹ç¼©åŒ…ä¸­æ²¡æœ‰å¯é¢„è§ˆçš„æ–‡æœ¬æ–‡ä»¶"
                else:
                    return "", "æ–‡ä»¶å·²åŠ å¯†ï¼Œæœªæä¾›è§£å‹å¯†ç "
            except Exception as e:
                logger.error(f"ä½¿ç”¨é»˜è®¤å¯†ç è§£å‹å¤±è´¥: {e}")
                return "", "è§£å‹å¤±è´¥"
        except Exception as e:
            logger.error(f"å¤„ç†ZIPæ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return "", "å¤„ç†ZIPæ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯"

        if not content_bytes:
            return "", "å‹ç¼©åŒ…ä¸­æ²¡æœ‰å¯é¢„è§ˆçš„æ–‡æœ¬æ–‡ä»¶"

        preview_text, encoding = self._get_preview_from_bytes(content_bytes)
        extra_info = f"ZIPå†…æ–‡ä»¶: {inner_filename} (æ ¼å¼ {encoding})"
        return f"{extra_info}\n{preview_text}", ""
    
    async def _get_file_preview(self, event: AstrMessageEvent, file_info: dict) -> tuple[str, str | None]:
        group_id = int(event.get_group_id())
        file_id = file_info.get("file_id")
        file_name = file_info.get("file_name", "")
        _, file_extension = os.path.splitext(file_name)
        
        is_txt = file_extension.lower() == '.txt'
        is_zip = self.enable_zip_preview and file_extension.lower() == '.zip'
        
        if not (is_txt or is_zip):
            return "", f"âŒ æ–‡ä»¶ã€Œ{file_name}ã€ä¸æ˜¯æ”¯æŒçš„æ–‡æœ¬æˆ–ZIPæ ¼å¼ï¼Œæ— æ³•é¢„è§ˆã€‚"
            
        logger.info(f"[{group_id}] æ­£åœ¨ä¸ºæ–‡ä»¶ '{file_name}' (ID: {file_id}) è·å–é¢„è§ˆ...")
        
        local_file_path = None
        
        try:
            bot = self._get_bot()
            if not bot:
                return "", "âŒ æ— æ³•è·å–æœºå™¨äººå®ä¾‹ï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚"
            client = bot
            url_result = await client.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
            if not (url_result and url_result.get('url')):
                return "", f"âŒ æ— æ³•è·å–æ–‡ä»¶ã€Œ{file_name}ã€çš„ä¸‹è½½é“¾æ¥ã€‚"
            url = url_result['url']
        except ActionFailed as e:
            if e.result.get('retcode') == 1200:
                error_message = (
                    f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ï¼š\n"
                    f"è¯¥æ–‡ä»¶å¯èƒ½å·²å¤±æ•ˆæˆ–è¢«æœåŠ¡å™¨æ¸…ç†ã€‚\n"
                    f"å»ºè®®ä½¿ç”¨ /df {os.path.splitext(file_name)[0]} å°†å…¶åˆ é™¤ã€‚"
                )
                return "", error_message
            else:
                return "", f"âŒ é¢„è§ˆå¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯ï¼š{e.result.get('wording', 'æœªçŸ¥é”™è¯¯')}"
        
        try:
            async with aiohttp.ClientSession() as session:
                async with self.download_semaphore:
                    # å¯¹äºZIPæ–‡ä»¶ï¼Œéœ€è¦ä¸‹è½½å®Œæ•´æ–‡ä»¶ï¼Œå› ä¸ºå¯èƒ½éœ€è¦å¯†ç è§£å‹
                    range_header = None
                    if is_txt:
                        range_header = {'Range': 'bytes=0-4095'}
                    async with session.get(url, headers=range_header, timeout=30) as resp:
                        if resp.status != 200 and resp.status != 206:
                            return "", f"âŒ ä¸‹è½½æ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ (HTTP: {resp.status})ã€‚"
                        
                        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                        temp_dir = os.path.join(os.getcwd(), 'temp_file_previews')
                        os.makedirs(temp_dir, exist_ok=True)
                        local_file_path = os.path.join(temp_dir, f"{file_id}_{file_name}")
                        
                        content_bytes = await resp.read()
                        with open(local_file_path, 'wb') as f:
                            f.write(content_bytes)
            
            preview_content = ""
            if is_txt:
                decoded_text, _ = self._get_preview_from_bytes(content_bytes)
                preview_content = decoded_text
            elif is_zip:
                preview_text, error_msg = await self._get_preview_from_zip(local_file_path)
                if error_msg:
                    return "", error_msg
                preview_content = preview_text
            
            if len(preview_content) > self.preview_length:
                preview_content = preview_content[:self.preview_length] + "..."
            
            return preview_content, None
                
        except asyncio.TimeoutError:
            return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€è¶…æ—¶ã€‚"
        except Exception as e:
            logger.error(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"
        finally:
            if local_file_path and os.path.exists(local_file_path):
                try:
                    os.remove(local_file_path)
                    logger.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {local_file_path}")
                except OSError as e:
                    logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {local_file_path} å¤±è´¥: {e}")

    async def terminate(self):
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²å¸è½½ã€‚")