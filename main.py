# astrbot_plugin_GroupFS/main.py

# è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–: pip install croniter aiohttp chardet
import asyncio
import os
import datetime
from typing import List, Dict, Optional

import aiohttp
import chardet
import croniter

from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
import astrbot.api.message_components as Comp
from astrbot.api.message_components import Node
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
from aiocqhttp.exceptions import ActionFailed

# ä» utils.py å¯¼å…¥è¾…åŠ©å‡½æ•°å’Œå¸¸é‡
from . import utils

@register(
    "astrbot_plugin_GroupFS",
    "Foolllll",
    "ç®¡ç†QQç¾¤æ–‡ä»¶",
    "0.7",
    "https://github.com/Foolllll-J/astrbot_plugin_GroupFS"
)
class GroupFSPlugin(Star):
    def __init__(self, context: Context, config: Optional[Dict] = None):
        super().__init__(context)
        self.config = config if config else {}
        self.group_whitelist: List[int] = [int(g) for g in self.config.get("group_whitelist", [])]
        self.admin_users: List[int] = [int(u) for u in self.config.get("admin_users", [])]
        self.preview_length: int = self.config.get("preview_length", 300)
        self.storage_limits: Dict[int, Dict] = {}
        self.cron_tasks = []
        self.last_cron_check_time: Dict[str, datetime.datetime] = {}
        self.bot = None
        self.forward_threshold: int = self.config.get("forward_threshold", 0)
        self.running_tasks = set()
        self.scheduler_lock = asyncio.Lock()

        # è§£æå®¹é‡ç›‘æ§é…ç½®
        limit_configs = self.config.get("storage_limits", [])
        for item in limit_configs:
            try:
                group_id_str, count_limit_str, space_limit_str = item.split(':')
                group_id = int(group_id_str)
                self.storage_limits[group_id] = { "count_limit": int(count_limit_str), "space_limit_gb": float(space_limit_str) }
            except ValueError as e:
                logger.error(f"è§£æ storage_limits é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        # è§£æå®šæ—¶ä»»åŠ¡é…ç½®
        cron_configs = self.config.get("scheduled_check_tasks", [])
        for item in cron_configs:
            try:
                group_id_str, cron_str = item.split(':', 1)
                group_id = int(group_id_str)
                if not croniter.croniter.is_valid(cron_str):
                    raise ValueError(f"æ— æ•ˆçš„ cron è¡¨è¾¾å¼: {cron_str}")
                task_key = f"{group_id}:{cron_str}"
                self.cron_tasks.append((task_key, group_id, cron_str))
            except ValueError as e:
                logger.error(f"è§£æ scheduled_check_tasks é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²åŠ è½½ã€‚")

    async def initialize(self):
        # åœ¨åˆå§‹åŒ–æ—¶ç›´æ¥è·å–å¹¶å­˜å‚¨ bot å®ä¾‹
        if hasattr(self.context, "bot") and self.context.bot:
            self.bot = self.context.bot
            logger.info("[åˆå§‹åŒ–] æˆåŠŸä» context ä¸­è·å– bot å®ä¾‹ã€‚")
        else:
            logger.warning("[åˆå§‹åŒ–] æœªèƒ½ä» context ä¸­ç›´æ¥è·å– bot å®ä¾‹ï¼Œå°†ä¾èµ–æŒ‡ä»¤è§¦å‘æ¥æ•è·ã€‚")

        if self.cron_tasks:
            logger.info("[å®šæ—¶ä»»åŠ¡] å¯åŠ¨å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥å¾ªç¯...")
            asyncio.create_task(self.scheduled_check_loop())

    async def _send_or_forward(self, event: AstrMessageEvent, text: str, name: str = "GroupFS"):
        if self.forward_threshold > 0 and len(text) > self.forward_threshold:
            group_id = event.get_group_id()
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°é•¿æ¶ˆæ¯ (é•¿åº¦: {len(text)} > {self.forward_threshold})ï¼Œå°†è‡ªåŠ¨åˆå¹¶è½¬å‘ã€‚")
            try:
                forward_node = Node(uin=event.get_self_id(), name=name, content=[Comp.Plain(text)])
                await event.send(MessageChain([forward_node]))
            except Exception as e:
                logger.error(f"[{group_id}] åˆå¹¶è½¬å‘é•¿æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
                await event.send(MessageChain([Comp.Plain(text[:self.forward_threshold] + "... (æ¶ˆæ¯è¿‡é•¿ä¸”åˆå¹¶è½¬å‘å¤±è´¥)")]))
        else:
            await event.send(MessageChain([Comp.Plain(text)]))

    async def scheduled_check_loop(self):
        await asyncio.sleep(10)
        while True:
            now = datetime.datetime.now()
            await asyncio.sleep(60 - now.second)
            
            async with self.scheduler_lock:
                now_aligned = datetime.datetime.now().replace(second=0, microsecond=0)
                for task_key, group_id, cron_str in self.cron_tasks:
                    if croniter.croniter.match(cron_str, now_aligned):
                        if task_key in self.running_tasks:
                            logger.warning(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ£€æµ‹åˆ°ä¸Šä¸€ä¸ªä»»åŠ¡ '{task_key}' ä»åœ¨è¿è¡Œï¼Œæœ¬æ¬¡è§¦å‘å·²è·³è¿‡ã€‚")
                            continue
                        logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] Cron è¡¨è¾¾å¼ '{cron_str}' å·²è§¦å‘ï¼Œå¼€å§‹æ‰§è¡Œã€‚")
                        self.running_tasks.add(task_key)
                        task = asyncio.ensure_future(self._perform_batch_check_for_cron(group_id))
                        task.add_done_callback(lambda t, key=task_key: self.running_tasks.remove(key))

    async def _perform_batch_check_for_cron(self, group_id: int):
        try:
            if not self.bot:
                logger.warning(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ— æ³•æ‰§è¡Œï¼Œå› ä¸ºå°šæœªæ•è·åˆ° bot å®ä¾‹ã€‚è¯·å…ˆè§¦å‘ä»»æ„ä¸€æ¬¡æŒ‡ä»¤ã€‚")
                return
            bot = self.bot
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹æ£€æŸ¥ã€‚")
            invalid_files_info = []
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    if not file_id: continue
                    try:
                        await bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            invalid_files_info.append(file_info)
                    await asyncio.sleep(0.2)
            if not invalid_files_info:
                logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ£€æŸ¥å®Œæˆï¼Œæœªå‘ç°å¤±æ•ˆæ–‡ä»¶ã€‚")
                return 
            report_message = f"ğŸš¨ å®šæ—¶æ£€æŸ¥æŠ¥å‘Š\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œå…±å‘ç° {len(invalid_files_info)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
            report_message += "-" * 20
            for info in invalid_files_info:
                folder_name = info.get('parent_folder_name', 'æœªçŸ¥')
                modify_time = utils.format_timestamp(info.get('modify_time'))
                report_message += f"\n- {info.get('file_name')}"
                report_message += f"\n  (æ–‡ä»¶å¤¹: {folder_name} | æ—¶é—´: {modify_time})"
            report_message += "\n" + "-" * 20
            report_message += "\nå»ºè®®ç®¡ç†å‘˜ä½¿ç”¨ /cdf æŒ‡ä»¤è¿›è¡Œä¸€é”®æ¸…ç†ã€‚"
            logger.info(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await bot.api.call_action('send_group_msg', group_id=group_id, message=report_message)
        except Exception as e:
            logger.error(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)

    async def _get_all_files_recursive_core(self, group_id: int, bot) -> List[Dict]:
        all_files = []
        folders_to_scan = [(None, "æ ¹ç›®å½•")]
        while folders_to_scan:
            current_folder_id, current_folder_name = folders_to_scan.pop(0)
            try:
                if current_folder_id is None:
                    result = await bot.api.call_action('get_group_root_files', group_id=group_id, file_count=2000)
                else:
                    result = await bot.api.call_action('get_group_files_by_folder', group_id=group_id, folder_id=current_folder_id, file_count=2000)
                if not result: continue
                if result.get('files'):
                    for file_info in result['files']:
                        file_info['parent_folder_name'] = current_folder_name
                        all_files.append(file_info)
                if result.get('folders'):
                    for folder in result['folders']:
                        if folder_id := folder.get('folder_id'):
                            folders_to_scan.append((folder_id, folder.get('folder_name')))
            except Exception as e:
                logger.error(f"[{group_id}] é€’å½’è·å–æ–‡ä»¶å¤¹ '{current_folder_name}' å†…å®¹æ—¶å‡ºé”™: {e}")
                continue
        return all_files
    
    @filter.command("cdf")
    async def on_check_and_delete_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cdf å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŒ‡ä»¤ã€‚")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        await event.send(MessageChain([Comp.Plain("âš ï¸ è­¦å‘Šï¼šå³å°†å¼€å§‹æ‰«æå¹¶è‡ªåŠ¨åˆ é™¤æ‰€æœ‰å¤±æ•ˆæ–‡ä»¶ï¼\næ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå®Œæˆåå°†å‘é€æŠ¥å‘Šã€‚")]))
        asyncio.create_task(self._perform_batch_check_and_delete(event))
        event.stop_event()

    async def _perform_batch_check_and_delete(self, event: AstrMessageEvent):
        group_id = int(event.get_group_id())
        try:
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, event.bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹å¤„ç†ã€‚")
            deleted_files = []
            failed_deletions = []
            checked_count = 0
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{ -(-total_count // batch_size)}...")
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    file_name = file_info.get("file_name", "æœªçŸ¥æ–‡ä»¶å")
                    if not file_id: continue
                    is_invalid = False
                    try:
                        await event.bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            is_invalid = True
                    if is_invalid:
                        logger.warning(f"[{group_id}] [æ‰¹é‡æ¸…ç†] å‘ç°å¤±æ•ˆæ–‡ä»¶ '{file_name}'ï¼Œå°è¯•åˆ é™¤...")
                        try:
                            delete_result = await event.bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
                            is_success = False
                            if delete_result:
                                trans_result = delete_result.get('transGroupFileResult', {})
                                result_obj = trans_result.get('result', {})
                                if result_obj.get('retCode') == 0:
                                    is_success = True
                            if is_success:
                                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æˆåŠŸåˆ é™¤å¤±æ•ˆæ–‡ä»¶: '{file_name}'")
                                deleted_files.append(file_name)
                            else:
                                logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] åˆ é™¤å¤±æ•ˆæ–‡ä»¶ '{file_name}' å¤±è´¥ï¼ŒAPIæœªè¿”å›æˆåŠŸã€‚")
                                failed_deletions.append(file_name)
                        except Exception as del_e:
                            logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] åˆ é™¤å¤±æ•ˆæ–‡ä»¶ '{file_name}' æ—¶å‘ç”Ÿå¼‚å¸¸: {del_e}")
                            failed_deletions.append(file_name)
                    checked_count += 1
                    await asyncio.sleep(0.2)
                logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œå·²æ£€æŸ¥ {checked_count}/{total_count} ä¸ªæ–‡ä»¶ã€‚")
            report_message = f"âœ… æ¸…ç†å®Œæˆï¼\nå…±æ‰«æäº† {total_count} ä¸ªæ–‡ä»¶ã€‚\n\n"
            if deleted_files:
                report_message += f"æˆåŠŸåˆ é™¤äº† {len(deleted_files)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
                report_message += "\n".join(f"- {name}" for name in deleted_files)
            else:
                report_message += "æœªå‘ç°æˆ–æœªæˆåŠŸåˆ é™¤ä»»ä½•å¤±æ•ˆæ–‡ä»¶ã€‚"
            if failed_deletions:
                report_message += f"\n\nğŸš¨ æœ‰ {len(failed_deletions)} ä¸ªå¤±æ•ˆæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å¤„ç†ï¼š\n"
                report_message += "\n".join(f"- {name}" for name in failed_deletions)
            logger.info(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await self._send_or_forward(event, report_message, name="å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŠ¥å‘Š")
        except Exception as e:
            logger.error(f"[{group_id}] [æ‰¹é‡æ¸…ç†] æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ åœ¨æ‰§è¡Œæ‰¹é‡æ¸…ç†æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    @filter.command("cf")
    async def on_check_files_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cf å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŒ‡ä»¤ã€‚")
        await event.send(MessageChain([Comp.Plain("âœ… å·²å¼€å§‹æ‰«æç¾¤å†…æ‰€æœ‰æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±æ•ˆæ–‡ä»¶...\nè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")]))
        asyncio.create_task(self._perform_batch_check(event))
        event.stop_event()

    async def _perform_batch_check(self, event: AstrMessageEvent, is_daily_check: bool = False):
        group_id = int(event.get_group_id())
        try:
            log_prefix = "[æ¯æ—¥è‡ªåŠ¨æ£€æŸ¥]" if is_daily_check else "[æ‰¹é‡æ£€æŸ¥]"
            logger.info(f"[{group_id}] {log_prefix} å¼€å§‹è·å–å…¨é‡æ–‡ä»¶åˆ—è¡¨...")
            all_files = await self._get_all_files_recursive_core(group_id, event.bot)
            total_count = len(all_files)
            logger.info(f"[{group_id}] {log_prefix} è·å–åˆ° {total_count} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡åˆ†æ‰¹æ£€æŸ¥ã€‚")
            invalid_files_info = []
            checked_count = 0
            batch_size = 50
            for i in range(0, total_count, batch_size):
                batch = all_files[i:i + batch_size]
                logger.info(f"[{group_id}] {log_prefix} æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{ -(-total_count // batch_size)}...")
                for file_info in batch:
                    file_id = file_info.get("file_id")
                    if not file_id: continue
                    try:
                        await event.bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
                    except ActionFailed as e:
                        if e.result.get('retcode') == 1200:
                            logger.warning(f"[{group_id}] {log_prefix} åˆ¤å®šå¤±æ•ˆæ–‡ä»¶: '{file_info.get('file_name')}'ï¼Œé”™è¯¯: {e.result.get('wording')}")
                            invalid_files_info.append(file_info)
                    checked_count += 1
                    await asyncio.sleep(0.2)
                logger.info(f"[{group_id}] {log_prefix} æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œå·²æ£€æŸ¥ {checked_count}/{total_count} ä¸ªæ–‡ä»¶ã€‚")
            report_title = "æ¯æ—¥æ£€æŸ¥æŠ¥å‘Š" if is_daily_check else "æ£€æŸ¥å®Œæˆï¼"
            if not invalid_files_info:
                report_message = f"ğŸ‰ {report_title}\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œæœªå‘ç°ä»»ä½•å¤±æ•ˆæ–‡ä»¶ã€‚"
            else:
                report_message = f"ğŸš¨ {report_title}\nåœ¨ {total_count} ä¸ªç¾¤æ–‡ä»¶ä¸­ï¼Œå…±å‘ç° {len(invalid_files_info)} ä¸ªå¤±æ•ˆæ–‡ä»¶ï¼š\n"
                report_message += "-" * 20
                for info in invalid_files_info:
                    folder_name = info.get('parent_folder_name', 'æœªçŸ¥')
                    modify_time = utils.format_timestamp(info.get('modify_time'))
                    report_message += f"\n- {info.get('file_name')}"
                    report_message += f"\n  (æ–‡ä»¶å¤¹: {folder_name} | æ—¶é—´: {modify_time})"
                report_message += "\n" + "-" * 20
                report_message += "\nå»ºè®®ä½¿ç”¨ /cdf æŒ‡ä»¤è¿›è¡Œä¸€é”®æ¸…ç†ã€‚"
            logger.info(f"[{group_id}] {log_prefix} æ£€æŸ¥å…¨éƒ¨å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
            await self._send_or_forward(event, report_message, name="å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŠ¥å‘Š")
        except Exception as e:
            logger.error(f"[{group_id}] {log_prefix} æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ åœ¨æ‰§è¡Œæ‰¹é‡æ£€æŸ¥æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))
    
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE, priority=10)
    async def on_group_file_upload(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        has_file = any(isinstance(seg, Comp.File) for seg in event.get_messages())
        if has_file:
            group_id = int(event.get_group_id())
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°æ–‡ä»¶ä¸Šä¼ äº‹ä»¶ï¼Œå°†åœ¨5ç§’åè§¦å‘å®¹é‡æ£€æŸ¥ã€‚")
            await asyncio.sleep(5) 
            await self._check_storage_and_notify(event)

    async def _check_storage_and_notify(self, event: AstrMessageEvent):
        group_id = int(event.get_group_id())
        if group_id not in self.storage_limits:
            return
        try:
            client = event.bot
            system_info = await client.api.call_action('get_group_file_system_info', group_id=group_id)
            if not system_info: return
            file_count = system_info.get('file_count', 0)
            used_space_bytes = system_info.get('used_space', 0)
            used_space_gb = float(utils.format_bytes(used_space_bytes, 'GB'))
            limits = self.storage_limits[group_id]
            count_limit = limits['count_limit']
            space_limit = limits['space_limit_gb']
            notifications = []
            if file_count >= count_limit:
                notifications.append(f"æ–‡ä»¶æ•°é‡å·²è¾¾ {file_count}ï¼Œæ¥è¿‘æˆ–è¶…è¿‡è®¾å®šçš„ {count_limit} ä¸Šé™ï¼")
            if used_space_gb >= space_limit:
                notifications.append(f"å·²ç”¨ç©ºé—´å·²è¾¾ {used_space_gb:.2f}GBï¼Œæ¥è¿‘æˆ–è¶…è¿‡è®¾å®šçš„ {space_limit:.2f}GB ä¸Šé™ï¼")
            if notifications:
                full_notification = "âš ï¸ ç¾¤æ–‡ä»¶å®¹é‡è­¦å‘Š âš ï¸\n" + "\n".join(notifications) + "\nè¯·åŠæ—¶æ¸…ç†æ–‡ä»¶ï¼"
                logger.warning(f"[{group_id}] å‘é€å®¹é‡è¶…é™è­¦å‘Š: {full_notification}")
                await event.send(MessageChain([Comp.Plain(full_notification)]))
        except ActionFailed as e:
            logger.error(f"[{group_id}] è°ƒç”¨ get_group_file_system_info å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†å®¹é‡æ£€æŸ¥æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
    
    def _format_search_results(self, files: List[Dict], search_term: str, for_delete: bool = False) -> str:
        reply_text = f"ğŸ” æ‰¾åˆ°äº† {len(files)} ä¸ªä¸ã€Œ{search_term}ã€ç›¸å…³çš„ç»“æœï¼š\n"
        reply_text += "-" * 20
        for i, file_info in enumerate(files, 1):
            reply_text += (
                f"\n[{i}] {file_info.get('file_name')}"
                f"\n  ä¸Šä¼ è€…: {file_info.get('uploader_name', 'æœªçŸ¥')}"
                f"\n  å¤§å°: {utils.format_bytes(file_info.get('size'))}"
                f"\n  ä¿®æ”¹æ—¶é—´: {utils.format_timestamp(file_info.get('modify_time'))}"
            )
        reply_text += "\n" + "-" * 20
        if for_delete:
            reply_text += f"\nè¯·ä½¿ç”¨ /df {search_term} [åºå·] æ¥åˆ é™¤æŒ‡å®šæ–‡ä»¶ã€‚"
        else:
            reply_text += f"\nå¦‚éœ€åˆ é™¤ï¼Œè¯·ä½¿ç”¨ /df {search_term} [åºå·]"
        return reply_text
    
    @filter.command("sf")
    async def on_search_file_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦æœç´¢çš„æ–‡ä»¶åã€‚ç”¨æ³•: /sf <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /sf, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        
        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)
        
        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ã€‚")

        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªåœ¨ç¾¤æ–‡ä»¶ä¸­æ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
        if not index_str:
            reply_text = self._format_search_results(found_files, filename_to_find)
            await self._send_or_forward(event, reply_text, name="æ–‡ä»¶æœç´¢ç»“æœ")
            return
        try:
            index = int(index_str)
            if not (1 <= index <= len(found_files)):
                await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                return
            file_to_preview = found_files[index - 1]
            preview_text, error_msg = await self._get_file_preview(event, file_to_preview)
            if error_msg:
                await event.send(MessageChain([Comp.Plain(error_msg)]))
                return
            reply_text = (
                f"ğŸ“„ æ–‡ä»¶ã€Œ{file_to_preview.get('file_name')}ã€å†…å®¹é¢„è§ˆï¼š\n"
                + "-" * 20 + "\n"
                + preview_text
            )
            await self._send_or_forward(event, reply_text, name=f"æ–‡ä»¶é¢„è§ˆï¼š{file_to_preview.get('file_name')}")
        except ValueError:
            await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ é¢„è§ˆæ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))
            
    @filter.command("df")
    async def on_delete_file_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦åˆ é™¤çš„æ–‡ä»¶åã€‚ç”¨æ³•: /df <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘åˆ é™¤æŒ‡ä»¤ /df, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return

        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)

        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ç”¨äºåˆ é™¤ã€‚")
            
        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªæ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
            
        if index_str == '0':
            asyncio.create_task(self._perform_batch_delete(event, found_files))
            event.stop_event()
            return

        file_to_delete = None
        if len(found_files) == 1 and not index_str:
            file_to_delete = found_files[0]
        elif index_str:
            try:
                index = int(index_str)
                if 1 <= index <= len(found_files):
                    file_to_delete = found_files[index - 1]
                else:
                    await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                    return
            except ValueError:
                await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
                return
        else:
            reply_text = self._format_search_results(found_files, filename_to_find, for_delete=True)
            await self._send_or_forward(event, reply_text, name="æ–‡ä»¶æœç´¢ç»“æœ")
            return

        if not file_to_delete:
            await event.send(MessageChain([Comp.Plain("âŒ å†…éƒ¨é”™è¯¯ï¼Œæœªèƒ½ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶ã€‚")]))
            return
        try:
            file_id_to_delete = file_to_delete.get("file_id")
            found_filename = file_to_delete.get("file_name")
            if not file_id_to_delete:
                await event.send(MessageChain([Comp.Plain(f"âŒ æ‰¾åˆ°æ–‡ä»¶ã€Œ{found_filename}ã€ï¼Œä½†æ— æ³•è·å–å…¶IDï¼Œåˆ é™¤å¤±è´¥ã€‚")]))
                return
            logger.info(f"[{group_id}] ç¡®è®¤åˆ é™¤æ–‡ä»¶ '{found_filename}', File ID: {file_id_to_delete}...")
            client = event.bot
            delete_result = await client.api.call_action('delete_group_file', group_id=group_id, file_id=file_id_to_delete)
            is_success = False
            if delete_result:
                trans_result = delete_result.get('transGroupFileResult', {})
                result_obj = trans_result.get('result', {})
                if result_obj.get('retCode') == 0:
                    is_success = True
            if is_success:
                await event.send(MessageChain([Comp.Plain(f"âœ… æ–‡ä»¶ã€Œ{found_filename}ã€å·²æˆåŠŸåˆ é™¤ã€‚")]))
                logger.info(f"[{group_id}] æ–‡ä»¶ '{found_filename}' å·²æˆåŠŸåˆ é™¤ã€‚")
            else:
                error_msg = delete_result.get('wording', 'APIæœªè¿”å›æˆåŠŸçŠ¶æ€')
                await event.send(MessageChain([Comp.Plain(f"âŒ åˆ é™¤æ–‡ä»¶ã€Œ{found_filename}ã€å¤±è´¥: {error_msg}")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†åˆ é™¤æµç¨‹æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain(f"âŒ å¤„ç†åˆ é™¤æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    async def _perform_batch_delete(self, event: AstrMessageEvent, files_to_delete: List[Dict]):
        group_id = int(event.get_group_id())
        deleted_files = []
        failed_deletions = []
        total_count = len(files_to_delete)
        logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] å¼€å§‹å¤„ç† {total_count} ä¸ªæ–‡ä»¶çš„åˆ é™¤ä»»åŠ¡ã€‚")
        for i, file_info in enumerate(files_to_delete):
            file_id = file_info.get("file_id")
            file_name = file_info.get("file_name", "æœªçŸ¥æ–‡ä»¶å")
            if not file_id:
                failed_deletions.append(f"{file_name} (ç¼ºå°‘File ID)")
                continue
            try:
                logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] ({i+1}/{total_count}) æ­£åœ¨åˆ é™¤ '{file_name}'...")
                delete_result = await event.bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
                is_success = False
                if delete_result:
                    trans_result = delete_result.get('transGroupFileResult', {})
                    result_obj = trans_result.get('result', {})
                    if result_obj.get('retCode') == 0:
                        is_success = True
                if is_success:
                    deleted_files.append(file_name)
                else:
                    failed_deletions.append(file_name)
            except Exception as e:
                logger.error(f"[{group_id}] [æ‰¹é‡åˆ é™¤] åˆ é™¤ '{file_name}' æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                failed_deletions.append(file_name)
            await asyncio.sleep(0.5)
        report_message = f"âœ… æ‰¹é‡åˆ é™¤å®Œæˆï¼\nå…±å¤„ç†äº† {total_count} ä¸ªæ–‡ä»¶ã€‚\n\n"
        if deleted_files:
            report_message += f"æˆåŠŸåˆ é™¤äº† {len(deleted_files)} ä¸ªæ–‡ä»¶ï¼š\n"
            report_message += "\n".join(f"- {name}" for name in deleted_files)
        else:
            report_message += "æœªèƒ½æˆåŠŸåˆ é™¤ä»»ä½•æ–‡ä»¶ã€‚"
        if failed_deletions:
            report_message += f"\n\nğŸš¨ æœ‰ {len(failed_deletions)} ä¸ªæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼š\n"
            report_message += "\n".join(f"- {name}" for name in failed_deletions)
        logger.info(f"[{group_id}] [æ‰¹é‡åˆ é™¤] ä»»åŠ¡å®Œæˆï¼Œå‡†å¤‡å‘é€æŠ¥å‘Šã€‚")
        await self._send_or_forward(event, report_message, name="æ‰¹é‡åˆ é™¤æŠ¥å‘Š")

    async def _get_file_preview(self, event: AstrMessageEvent, file_info: dict) -> tuple[str, str | None]:
        group_id = int(event.get_group_id())
        file_id = file_info.get("file_id")
        file_name = file_info.get("file_name", "")
        _, file_extension = os.path.splitext(file_name)
        if file_extension.lower() not in utils.SUPPORTED_PREVIEW_EXTENSIONS:
            return "", f"âŒ æ–‡ä»¶ã€Œ{file_name}ã€ä¸æ˜¯æ”¯æŒçš„æ–‡æœ¬æ ¼å¼ï¼Œæ— æ³•é¢„è§ˆã€‚"
        logger.info(f"[{group_id}] æ­£åœ¨ä¸ºæ–‡ä»¶ '{file_name}' (ID: {file_id}) è·å–é¢„è§ˆ...")
        try:
            client = event.bot
            url_result = await client.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
        except ActionFailed as e:
            logger.warning(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' ä¸‹è½½é“¾æ¥æ—¶APIè°ƒç”¨å¤±è´¥: {e}")
            if e.result.get('retcode') == 1200:
                error_message = (
                    f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ï¼š\n"
                    f"è¯¥æ–‡ä»¶å¯èƒ½å·²å¤±æ•ˆæˆ–è¢«æœåŠ¡å™¨æ¸…ç†ã€‚\n"
                    f"å»ºè®®ä½¿ç”¨ /df {os.path.splitext(file_name)[0]} å°†å…¶åˆ é™¤ã€‚"
                )
                return "", error_message
            else:
                return "", f"âŒ é¢„è§ˆå¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯ï¼š{e.result.get('wording', 'æœªçŸ¥é”™è¯¯')}"
        try:
            if not (url_result and url_result.get('url')):
                return "", f"âŒ æ— æ³•è·å–æ–‡ä»¶ã€Œ{file_name}ã€çš„ä¸‹è½½é“¾æ¥ã€‚"
            url = url_result['url']
            async with aiohttp.ClientSession() as session:
                headers = {'Range': 'bytes=0-4095'} 
                async with session.get(url, headers=headers, timeout=20) as resp:
                    if resp.status != 200 and resp.status != 206:
                        return "", f"âŒ ä¸‹è½½æ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ (HTTP: {resp.status})ã€‚"
                    content_bytes = await resp.read()
            if not content_bytes:
                return "ï¼ˆæ–‡ä»¶ä¸ºç©ºï¼‰", None
            detection = chardet.detect(content_bytes)
            encoding = detection.get('encoding', 'utf-8') or 'utf-8'
            decoded_text = content_bytes.decode(encoding, errors='ignore').strip()
            if len(decoded_text) > self.preview_length:
                return decoded_text[:self.preview_length] + "...", None
            return decoded_text, None
        except asyncio.TimeoutError:
            return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€è¶…æ—¶ã€‚"
        except Exception as e:
            logger.error(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"
            
    async def terminate(self):
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²å¸è½½ã€‚")